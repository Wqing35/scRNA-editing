{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sample in ['GW08','GW12','GW16_1_3', 'GW16_1_9', 'GW19_1_1', 'GW19_1_2', 'GW19_1_3', 'GW23_1_1', 'GW23_1_2', 'GW23_1_3']:\n",
    "for sample in ['GW26_1_1']:\n",
    "    res_in_dir='/disk1/wenqing/tmp_data/PFC_s2/result/'+sample+'/GABAergic_neurons/tmp/readInfo_dpFiltered/tmp/regular.res'\n",
    "    res_data=pd.read_csv(res_in_dir,sep='\\t',header=None)\n",
    "    read_wz_iso='/disk1/wenqing/tmp_data/PFC_s2/result/'+sample+'/GABAergic_neurons/tmp/genome/readID_wz_iso_hasRes.clean.txt'\n",
    "    read_wz_iso_info=pd.read_csv(read_wz_iso,sep='\\t',header=None)\n",
    "    all_as_type=['RI','A3','A5','AF','AL','MX','SE']\n",
    "    all_as_type=['RI']\n",
    "    for type in all_as_type:\n",
    "        #AS\n",
    "        bed_in_dir='/disk1/wenqing/tmp_data/SUPPA2/ref/'+type+'_as_events.bed'\n",
    "        fi=open(bed_in_dir)\n",
    "        all_res_num=[]\n",
    "        for line in fi:\n",
    "            seq=line.rstrip().split('\\t')\n",
    "            transcript=seq[4]\n",
    "            chr=seq[0]\n",
    "            ts_start=int(seq[1])\n",
    "            ts_end=int(seq[2])\n",
    "            #提取和当前转录本对应的reads\n",
    "            ts_related_reads=read_wz_iso_info[read_wz_iso_info.iloc[:, 1] == transcript].iloc[:, 0]\n",
    "            #根据reads提取res子表，写入一临时文件，并调用bedtools计算每一个转录本region的res数量\n",
    "            reads_related_rs = res_data[res_data.iloc[:, 6].isin(ts_related_reads)]\n",
    "            num=0\n",
    "            if len(reads_related_rs.index)!=0:\n",
    "                for index in range(0,len(reads_related_rs.index)):\n",
    "                    res_chr=str(reads_related_rs.iloc[index,0])\n",
    "                    res_end=int(reads_related_rs.iloc[index,2])\n",
    "                    res_type=str(reads_related_rs.iloc[index,3])\n",
    "                    if res_chr==chr and res_end <= ts_end and res_type==\"AG\":\n",
    "                        num+=1 \n",
    "            all_res_num.append(num)\n",
    "        fi.close()    \n",
    "\n",
    "        transcript_region=pd.read_csv(bed_in_dir,sep='\\t',header=None)\n",
    "        transcript_region[transcript_region.columns.max()+1]=all_res_num\n",
    "        bed_out_dir='/disk1/wenqing/tmp_data/PFC_s2/all_analysis_result/EI_in_reads/'+sample+'/'+type+'_as_events_wzResNum.1.txt'\n",
    "        transcript_region.to_csv(bed_out_dir,sep='\\t',header=None,index=False)\n",
    "\n",
    "        #nonAs\n",
    "        bed_in_dir='/disk1/wenqing/tmp_data/SUPPA2/ref/'+type+'_nonAs_events.bed'\n",
    "        fi=open(bed_in_dir)\n",
    "        all_res_num=[]\n",
    "        for line in fi:\n",
    "            seq=line.rstrip().split('\\t')\n",
    "            transcript=seq[4]\n",
    "            chr=seq[0]\n",
    "            ts_start=int(seq[1])\n",
    "            ts_end=int(seq[2])\n",
    "            #提取和当前转录本对应的reads\n",
    "            ts_related_reads=read_wz_iso_info[read_wz_iso_info.iloc[:, 1] == transcript].iloc[:, 0]\n",
    "            #根据reads提取res子表，写入一临时文件，并调用bedtools计算每一个转录本region的res数量\n",
    "            reads_related_rs = res_data[res_data.iloc[:, 6].isin(ts_related_reads)]\n",
    "            num=0\n",
    "            if len(reads_related_rs.index)!=0:\n",
    "                for index in range(0,len(reads_related_rs.index)):\n",
    "                    res_chr=str(reads_related_rs.iloc[index,0])\n",
    "                    res_end=int(reads_related_rs.iloc[index,2])\n",
    "                    res_type=str(reads_related_rs.iloc[index,3])\n",
    "                    if res_chr==chr and res_end <= ts_end and res_type==\"AG\":\n",
    "                        num+=1 \n",
    "            all_res_num.append(num)\n",
    "        fi.close()    \n",
    "\n",
    "        transcript_region=pd.read_csv(bed_in_dir,sep='\\t',header=None)\n",
    "        transcript_region[transcript_region.columns.max()+1]=all_res_num\n",
    "        bed_out_dir='/disk1/wenqing/tmp_data/PFC_s2/all_analysis_result/EI_in_reads/'+sample+'/'+type+'_nonAs_events_wzResNum.txt'\n",
    "        transcript_region.to_csv(bed_out_dir,sep='\\t',header=None,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 ('wq_py2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3d9b3e1c6b1fa0ff695134d55cceda29208d4e881196dda1f6264c2c158467a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
